---
title: '`baselinenowcast` Analysis Pipeline'
author: "Kaitlyn Johnson"
date: "2025-03-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

# Introduction

This document defines the analysis pipeline used to evaluate the performance
of the `baselinenowcast` R package, which is intended to be used as a
baseline method for nowcasting right-truncated epidemiological data.
More details on the method can be found in the `baselinenowcast` repository.

The performance of the baseline nowcast method will be evaluated as follows:
1. Applied to real-world data from the German Nowcast Hub from 1 Dec 2021 to
1 April 2022, nationally, by age group, and by state.
2. Applied to 4 simulated data scenarios in which we take two age strata, one
sparse and one rich from the German Nowcast data, and apply a long and short
delay to the data. For each data scenario, we will assess 24 different
combinations of model specifications
3. Applied to real-world data from 1. 2013-2014 Measles outbreak in the
Netherlands 2. 2023-2024 Norovirus outbreak in the UK and 3. Comparison of
performance of the mean/median ensemble in the German Nowcast Hub

This workflow uses the `targets` package.

```{r, eval = FALSE}
rmarkdown::render("_targets.Rmd")
```

The pipeline can be run using,
```{r, eval = FALSE}
tar_make()
```

# Setup

Set up the workflow pipeline.
```{r}
library(targets)
library(crew)
library(RcppTOML)
library(readr)
```

Define the shared global options and load the R functions from the `R` folder
```{targets globals, tar_globals = TRUE}
library(targets)
library(tarchetypes)
library(ggplot2)
library(purrr, quietly = TRUE)
library(arrow)
library(here)
functions <- list.files(here("R"), full.names = TRUE)
walk(functions, source)
rm("functions")

tar_option_set(
  packages = c(
    "tibble", "dplyr", "lubridate",
    "baselinenowcast",
    "readr", "epinowcast", "tidyr"
  ),
  workspace_on_error = TRUE,
  # Setup storage on workers vs on the main node.
  memory = "transient",
  format = "rds", # default storage format
  error = NULL # tells errored targets to return NULL rather than
  # have whole pipeline fail
)
```

# Methods

We'll start by gathering all of the datasets and model specifications that we
need for each of the component analyses

## Real-world data from German Nowcast Hub

### Create reporting triangles as of daily nowcast dates

### Create evaluation data
This will be as of each of the nowcast dates + the evaluation time frame (e.g.
80 days)

### Model specification for German nowcast data
Specify the maximum delay, number of reference times to use for delay
estimation, number of reporting triangles to use for dispersion estimate, and
whether or not delay estimates/dispersion parameters are being borrowed

## Simulated data, modified from German Nowcast Hub

## Create simulated reporting triangles as of nowcast dates from final reports
This will be for two age strata only, and with a long and short
delay, creating 4 distinct datasets

### Create evaluation data for simulated data
This will be from simulated data as of nowcast date + eval time frame (e.g. 80
days)

### Model specification(s) for simulated data
Make all combinations of varying:
- max delay
- borrowing for delay estimation
- borrowing for dispersion estimate
- number of observations for delay estimation
- number of reporting triangles for dispersion estimate

## Real-world case data: Measles and norovirus

### Load and clean measles data
```{targets measles_line_list, tar_simple = TRUE}
read.delim("https://raw.githubusercontent.com/kassteele/Nowcasting/refs/heads/master/data/measles_NL_2013_2014.dat", sep = "") |>
  mutate(reference_date = ymd(onset.date),
         report_date = ymd(report.date)) |>
  select(reference_date, report_date)
```
Convert from line list to a long tidy dataframe with counts by reference and
report date
```{targets measles_long, tar_simple = TRUE}
measles_line_list |>
  group_by(reference_date, report_date) |>
  summarise(confirm = n()) |>
  ungroup() |>
  complete(reference_date = seq(from = min(reference_date),
                                to = max(reference_date),
                                by = "day"),
           report_date = seq(from = min(reference_date),
                                to = max(report_date),
                                by = "days")) |>
  mutate(confirm = ifelse(is.na(confirm), 0, confirm))
```
```{targets nowcast_dates, tar_simple = TRUE}
data.frame(
    nowcast_date = c("2024-01-21", "2024-01-28")
  )
```
### Create reporting triangles as of daily nowcast dates
```{targets measles_rt}
tar_group_by(
  measles_rt,
  enw_filter_report_dates(measles_long,
                          latest_date = nowcast_dates$nowcast_date) |>
# Make reporting triangle by hand
  mutate(delay = as.integer(difftime(report_date,
                                     reference_date,
                                     units = "days"))) |>
  select(reference_date, delay, confirm) |>
  filter(delay <= 50, delay >=0) |>
  pivot_wider(names_from = delay,
              values_from = confirm),
pattern = map(nowcast_dates)
)

```

### Load in norovirus data

### Create reporting triangles as of daily nowcast dates

### Create evaluation data for both at nowcast dates + eval time frame

### Model specification for each data set
Based off of the specific dataset, make a single choice about a specification

# Results

## Run `baselinenowcast` model

### Use tar_map or tar_group_by to run the model on all datasets

#### Generate outputs for each model run joined to corresponding metadata
  - scores (from samples)
  - scores (from quantiles; e.g. calibration but also WIS scores)
  - quantiled nowcasts for visual comparison

### Figures for real-world case study German Nowcast Hub

### Figures for simulated data case study with different model specifications

### Figures for norovirus and measles

### Consolidate evaluation data from mean/median ensemble in GNH & our run

### Make figures comparing performance of baselinenowcats and ensembles
