---
title: "Supplement: A baseline method for nowcasting count data"
authors: "To be updated"
format: docx
editor: visual
date: 2025-04-16
bibliography: ref.bib
output:
  bookdown::docx:
    fig_caption: yes
---

# Supplemental methods

## Mathematical model

This model was initially developed as a reference model for the COVID-19 hospitalisation nowcast challenge in Germany in 2021 and 2022 @Wolffram2023. It uses preliminary case count and their delays in the form of reporting triangles, and uses empirical delay distributions to estimate yet-to-be-observed cases. Probabilistic nowcasts are generated using a negative binomial model with means from the point nowcast and dispersion parameters estimated from past nowcast errors. Below, we describe the mathematical details of each component of the model, starting with a definition of the notation used throughout.

### Notation

We denote $X_{t,d}, d = 0, .., D$ as the number of cases occurring on time $t$ which appear in the dataset with a delay of $d$. For example, a delay $d = 0$ means that a case occurring on day $t$ arrived in the dataset on day $t$, or on what is considered to be the first possible report date in practice. We only consider cases reporting within a maximum delay $D$. The number of cases reporting for time $t$ with a delay of at most $d$ can be written as:

$$X_{t, \le d} = \sum_{i=0}^d X_{t,i} $$

A special case of this is the "final" number of reported cases at time $t$, $X_t$:

$$
X_t = X_{t, \le D} = \sum_{i=0}^D X_{t,i}
$$

Conversely, for delays less than the maximum delay $d < D$, we defined $X_{t,>d}$ by

$$X_{t,>d} = \sum_{i = d+1} ^{D} X_{t,i}$$

representing the number of cases still missing after $d$ delay. We refer to $X_t$ to describe a random variable, $x_t$ for the corresponding observation, and $\hat{x}_t$ for an estimated/imputed value. The matrix of $x_{t,d}$ available at a given time $t^*$ is referred to as a reporting matrix. In the case where all $t+d>t^*$ have yet to be observed (e.g. $t^*$ is the current time), this reporting matrix is referred to as the reporting triangle, with all values in the bottom right corner of the triangle being missing, except for the first entry at $x_{t=t*, d = 0}$.

|   | $d = 0$ | $d = 1$ | $d=2$ | $...$ | $d= D-1$ | $d= D$ |
|----|----|----|----|----|----|----|
| $t=1$ | $x_{1,0}$ | $x_{1,1}$ | $x_{1,2}$ | $...$ | $x_{1,D-1}$ | $x_{1, D}$ |
| $t=2$ | $x_{2,0}$ | $x_{2,1}$ | $x_{2,2}$ | $...$ | $x_{2,D-1}$ | $x_{2, D}$ |
| $t=3$ | $x_{3,0}$ | $x_{3,1}$ | $x_{3,2}$ | $...$ | $x_{3,D-1}$ | $x_{3, D}$ |
| $...$ | $...$ | $...$ | $...$ | $...$ | $...$ | $...$ |
| $t=t^*-1$ | $x_{t^*-1,0}$ | $x_{t^*-1,1}$ | $x_{t^*-1,,2}$ | $...$ | $x_{t^*-1,,D-1}$ | $x_{t^*-1,D}$ |
| $t=t^*$ | $x_{t^*,0}$ | $x_{t^*,1}$ | $x_{t^*,2}$ | $...$ | $x_{t^*,D-1}$ | $x_{t^*, D}$ |

### Delay distribution estimation

#### Estimate of the delay distribution from a reporting matrix

We can use a reporting matrix to compute an empirical estimate of the delay distribution, $\pi_d$. The empirical delay distribution, $\pi_d$ can be computed directly from the reporting matrix $X$ using the latest $N$ reference times via:

$$
\pi_d= \frac{\sum_{t=t^*-N+1}^{t=t^*} X_{t,d}}{\sum_{d'=0}^{D} \sum_{t=t^*-N+1}^{t=t^*} X_{t,d'}}
$$ {#eq:pi_d}

Where the numerator is the sum of all the observations across reference times $t$ for a particular delay $d$ of interest, and the denominator is the sum across all reference times $t$ and indexed delays in the reporting matrix $d'$.

#### Multiplicative model

In the case where we have missing values in the bottom right (i.e. we have a reporting triangle), the estimator $\pi_d$ can only be evaluated as written in \@ref(eq:pi_d) after discarding all data from the last $D-1$ time points. In order to use the partial information contained in the most recent $D-1$ time points, we use a different representation of the delay distribution via terms of the form:

$$
\theta_d = \frac{\pi_d}{\pi_{\le d-1}}
$$ {#eq:theta_d}

Where 

$$
\pi_{\le d-1} = \sum_{d'=0}^{d-1} \pi_d
$$ {#eq:pi_less_than_d}

These $\theta_d$ can be estimated via the equation above \@ref(eq:theta_d) and translated to $\pi_1,...,\pi_D$ via the recursion

$$
\pi_{\leq d} = (1+\theta_d)\pi_{\leq d-1}
$$

Subject to the constrain that $\sum \pi_i = 1$.


![Visual description of the iterative “completing” of the reporting triangle, moving from left to right and bottom to top. In this cases, we are imputing \$x\_{t=6, d = 2}\$ and \$x\_{t=5, d= 2}\$ assuming that the ratio between \$x\_{t=1:4, d = 2}\$ (block top), and \$x\_{t=1:4, d=0:1}\$ (block top left) holds for for \$x\_{t=5:6, d = 2}\$ (block bottom) and \$x\_{t=5:6, d = 0:1}\$ (block bottom left). In this example, \$\\hat{x}\_{t=6, d = 1}\$ has already been imputed using the same approach, and we treat it as known going forward. This process is repeated across the reporting triangle to estimate all values outlined in the dashed lines.](schematic_fig.png){#fig1} <!--Noting that this caption should probably be written to refer back to theta and pi_d. My understanding is that theta is basically block top/ block top left, and we get block bottom by assuming the equivalence of  block top/block top left = block bottom/ block bottom left. -->

The method requires at least one observation, at delay $d=0$ for the most recent reference time, located at the bottom left of the reporting triangle in Figure \@ref(fig1) above.

The intuition behind the multiplicative method is the assumption that the values at each delay $d$ for the recent times, will consist of the same proportion of the values previously reported for earlier times. To fill in the missing values for each column $d$, we sum over the rectangle of completely observed reference dates for all $d-1$ columns (block top left) and sum over the column of completely observed reference dates for all of the entries in column $d$ (block left). The ratio of these two sums, $\theta_d$, is assumed to be the same in the missing entries in column $d$, so we use the entries observed up to $d-1$ for each incomplete reference date (block bottom left), and scale by this ratio to get the missing entries in column $d$. This process is repeated for each delay from $d$ up to the maximum delay $D$. At each iteration an additional reference time entry is computed as the delay $d$ increases.

The delay distribution is estimated from the filled in reporting matrix per \@ref(eq:pi_d). It is worth noting that the resulting imputed values in the bottom right of the reporting triangle do not have an effect on the delay distribution, as they are chosen such that they correspond almost precisely to the distribution seen in the combination of the complete and partial rows. The slight imprecision is due to the additional component incorporated to handle 0s in observations of $x_{t>t^*-d, d}$. See [Zero-handling](#zero-handling-approximation) for further details.

### Point nowcast generation

To obtain a point nowcast matrix from a reporting triangle and any arbitrary delay PMF, $\pi_d$, we need to estimate the expected total number of eventual observed cases $\hat{x}_t$, for each reference time $t$. Let $x_{\leq t^*-t}$ be the sum over all delays $d$ that have already been observed (up until $t^*-t$), such that $x_{\leq t^*-t} =\sum_{d=1}^{d=t^*-t} x_{t,d}$ and $\pi_{\leq t^*-t}$ be the cumulative sum of the delay distribution, $\pi_d$ up until $d = t^*-t$ such that $\pi_{\leq t^*-t}= \sum_{d=1}^{d=t^*-t} \pi_d$. It can be shown (See [Zero-handling](#zero-handling-approximation) below) that the expected value of $X_t$, the total number of reported cases on reference time $t$, can be written as:

$$
E(X_t | x_{\leq t^*-t}, \pi_{\leq t^*-t}) = \hat{x}_t = \frac{x_{\leq t^*-t} + 1 - \pi_{\leq t^*-t}}{\pi_{\leq t^*-t}}
$$

Then we can compute the missing elements of the point nowcast matrix $\hat{x}_{t,d}$ directly using the $d$th element of $\pi_d$

$$
\hat{x}_{t,d} = \pi_d \times \hat{x}_t
$$

Where the expected count at timepoint $t$ with delay $d$ is the product of the the expected total count, $\hat{x}_t$ and the proportion expected at that particular delay $d$, $\pi_d$. We will use the individual elements of the point nowcast matrix, $\hat{x}_{t,d}$ for uncertainty quantification.

### Uncertainty quantification

To estimate the uncertainty in the nowcasts, we use past nowcast errors. In this analysis, we assume a negative binomial observation model.

#### Generation of retrospective reporting triangles

We describe a method which generates retrospective reporting triangles to replicate what would have been available as of times$s^* = t^*-1, ..., t^*-M$ to generate $M$ retrospective reporting triangles.

To generate the set of $M$ reporting triangles, we work backwards from most recent to oldest, removing the last $m$ rows of the current reporting triangle, to generate $M$ truncated reporting triangles. We then subsequently remove values which would not have been availbale as of each $s^*$, to generate $M$ retrospective reporting triangles.

#### Generation of retrospective point nowcast matrices

From the $M$ reporting triangles, we apply the method described above to estimate a delay distribution using the $N$ preceding reference times and generate a point nowcast for each retrospective reporting triangle, to generate $M$ point nowcasts.

Thus in order to estimate uncertainty using $N$ reference times, the total training volume must meet or exceed $N+M$ so that the oldest retrospective nowcast dataset at $s^* = t^*-M$ can use $N$ reference times for its point nowcast.

#### Fit predicted point nowcast vectors and observed counts to a negative binomial observation model at each forecast horizon

We quantify the uncertainty in the component of the target that corresponds to the counts that are still to be added. The default in the package assumes that the target is the final count at each reference time, summed across reporting delays, however, for the COVID-19 case study, the target is defined as the 7-day rolling sum of the counts at reference time, and therefore the uncertainty is quantified in the component of this quantity that has yet to be observed as of each reference time.

At each retrospective nowcast time $s^*$, we compute the predicted and corresponding observed nowcast at each forecast horizon $j = 1, ..., D$ by summing across the reporting delays for all delays $d$ that have been observed as of time $t^*$, as indicated below by the indicator function, for the retrospective nowcast $\hat{X}_{s^*,d}$ and the truncated observed component $x_{t= s^*,d}$. We define the component of the retrospective nowcast that is predicted as of $s^*$, but observed as of $t^*$ as:

$$
\hat{X}_{s^*-j}(s^* >d) = \sum_{d=0}^{D} \hat{X}_{s^*-j,d} \times I(s^*-j+d \leq t^*)
$$ and likewise the corresponding component that has been observed as of $t^*$ for each retrospective nowcast time $s^*$ as: $$
x_{s^*-j}(s^*> d) = \sum_{d=0}^{D} x_{s^*-j,d} \times I(s^*-j+d \leq t^*)
$$

This generates $M$ pairs of predicted nowcast vectors and corresponding later observed nowcast vectors for each forecast horizon $j = 1, ..., D$. We assume that the later observed nowcasts vectors $x_{s^*-j, >d}$ follow a negative binomial observation model with a mean of $\hat{X}_{s^*-j}(s^*-j)$ <!-- Leaving in the +0.1 for now because we still use this to estimate, need to discuss, I now do not think we need it because the mean will never be 0-->

$$
x_{s^*-j} | \hat{X}_{s^*-j}(j) \sim \text{NegBin}(\mu = \hat{X}_{s^*-j}(s^*-j) + 0.1, disp= \phi_j)
$$ for all $s^* = 1, ..., M$.

We add a small number (0.1) to the mean to avoid an ill-defined negative binomial. This generates a vector of negative binomial dispersion parameters indexed starting at forecast horizon $j=1$.

### Probabilistic nowcast generation

Using the dispersion parameters for each forecast horizon, $\phi_j,$ for $j = 1,...D$, we can generate probabilistic nowcast matrices by drawing samples from the negative binomial for the sum over the still missing counts:

$$
X_{t^*-j, >d} \sim NegBin(\mu = \hat{X}_{t^*-j, >d}, \phi = \phi(j))
$$

We can sample for any number of draws, and then use the draws to compute any desired quantiles to summarize the outputs.

### Zero-handling approximation {#zero-handling-approximation}

In order to produce a nowcast for a specific reference date, we use the number of already observed cases, $x_{t,\leq_d}$ and the delay PMF, $\pi$ to estimate the expected final count of cases $X_{t} = \sum_{d=1}^D X_{t,d}$. We will assume a simple binomial reporting model to derive an approximation for the expectation $E(X_t | X_{t, \leq d},\pi_\leq d)$.

For notational simplicity, we will refer to $X_{t}$ as $N$, to indicate the random variable for the total number of final cases at a particular reference time $t$, and $X_{t,d}$ as $X$ to indicate the random variable for the number of cases at a particular reference time $t$ and delay $d$.

We will denote the CDF of the delay distribution at a particular delay $d$, $\sum_{d=0}^d \pi_d$ simply by $p$.

However, this simple calculation is undefined when the number of already observed cases is 0.

The following derivation addresses this practical issue based on assumptions about the underlying distributions for which the observed cases at each reference time and reporting delay are drawn from.\

Our problem boils down to the following. If we assume that: $$
X | N \sim Bin(N, p)
$$ with $\pi$ known and an improper discrete uniform prior on $N$: $$
\text{pr}(N= n) \propto C \text{ for n = 0, 1, 2, ...}
$$ We are then interested in: $$
\mathbb{E}[N | X = x]
$$ This can be written out as: $$
\mathbb{E}[N | X = x] = \sum_{n=0}^{\infty}\text{P}(N = n | X = x) n
$$ Applying Bayes Theorem we have: $$
\text{P}(N = n | X = x)  = \frac{\text{P}(X = x | N = n) \text{P}(N=n)}{\sum_{i=0}^{\infty}\text{P}( X = x | N= i) \text{P}(N = i)}
$$ Because $\text{P}(N=n) \propto C$ this simplifies to:

$$
\text{P}(N = n | X = x)  = \frac{\text{P}(X = x | N = n)}{\sum_{i=0}^{\infty}\text{P}( X = x | N= i)}
$$

And substituting the probability mass function of the binomial distribution $f(x) = P[X = x| N = n] =\binom{n}{x} p^x(1-p)^{n-x}$ we get:

$$
\text{pr}(N = n | X = x) = \frac{\binom{n}{x} p^x(1-p)^{n-x}}{\sum_{i=1}^\infty \binom{1}{x}p^x(1-p)^{i-x}}
$$

Plugging into $\mathbb{E}[N | X = x] = \sum_{n=0}^{\infty}\text{P}(N = n | X = x) n$ we get the following (omitting terms for $n<x$, which are 0):

$$
\mathbb{E}[N | X = x] = \sum_{n=x}^{\infty}n \frac{\binom{n}{x} p^x(1-p)^{n-x}}{\sum_{i=x}^\infty \binom{i}{x}p^x(1-p)^{i-x}}
$$

Which is equivalent to:

$$
\mathbb{E}[N | X = x] =  \frac{\sum_{n=x}^{\infty}n \binom{n}{x} p^x(1-p)^{n-x}}{\sum_{i=x}^\infty \binom{i}{x}p^x(1-p)^{i-x}}
$$

Both the numerator and the denominator are known convergent series, with solutions available in standard libraries like Mathematica. We then get:

$$
\mathbb{E}[N | X = x]  = \frac{(x + 1 -p)/p^2}{1/\pi} = \frac{x + 1 - p}{p}
$$ This formula allows us to have a defined $\mathbb{E}[N | X = x]$ even when $X = 0$.

### Description of KIT simple nowcast implementation issue and revised nowcasts

When verifying the KIT simple nowcast implementation, we noticed that the code used to generate the KIT simple nowcasts in real-time contained an additional indexed element in the delay PMF for all counts observed beyond the maximum delay thus far. In the generation of retrospective nowcasts, these values were being handled as having been observed as 0s, when in fact they had yet to be observed in all of the retrospective nowcasts. This resulted in a comparison of a 0 to a later observed value – which has the impact of inflating the dispersion estimates, and may explain why the KIT simple nowcast method in Wolffram et al. [@Wolffram2023] overcovers relative to the other methods. In the latest implementation in the RESPINOW Hub [@respinow_hub_2025], the authors have removed the density beyond the maximum delay column from their implementation, and thus it no longer contains this issue.

In order to validate our `baselinenowcast` method against a revised version with the bug fixed, we regenerated the nowcasts using the pre-processed reporting triangle in the German Nowcast Hub repository [@hospitalization_nowcast_hub_2025] and generated retrospective nowcasts, referring to these in the main text and supplement as the KIT simple nowcast revised.

## Additional figures

### German nowcast Hub validation using revised KIT simple nowcast

![Fig.S1 Validation of baseline nowcasting model using German COVID-19 data compared to revised KIT simple nowcast. A. Weekly nowcasts from our baseline model and the KIT simple nowcast revised model against eventually observed national values, coloured by model, with data available at nowcast date (dotted lines). Nowcasts are shown daily with a 14-day horizon. B. Overall performance comparison between models, with decomposed WIS (dispersion, overprediction, underprediction) displayed as stacked bar charts for direct comparison. Stratified by national and age group nowcasts. C. Performance over time, displaying daily mean WIS scores summarised across age strata and 28 horizon days, coloured by model. D. Performance by age group, showing WIS scores across different age groups on the x axis with grouped bars for both models and stacked components displaying the decomposition of scores. E. Mean reporting delay over time, visualised as multiple coloured lines representing each age group, with the national average shown as a thicker black line. F. Empirical coverage at 50% and 90% prediction intervals for each model.](../output/figs/supp/fig_hub_validation_vs_KIT_revised.png){#figs1}

![Fig.S2 Relative WIS by age group.](../output/figs/supp/rel_wis_by_age_group.png){#figs2}

![Fig.S3 Mean WIS by nowcast horizon for each model—same panel relative WIS by nowcast horizon.](../output/figs/supp/mean_wis_by_horizon_ag.png){#figs3}

![Fig.S4. Relative WIS by nowcast horizon](../output/figs/supp/rel_wis_by_horizon_ag.png){#figs4}

![Fig.S5 Empirical coverage at 50% and 90% prediction intervals](../output/figs/supp/bar_chart_cov_ag.png){#figs5}

![Fig.S6 Empirical coverage at 50% and 90% prediction intervals by horizon for each model.](../output/figs/supp/cov_by_horizon_ag.png){#figs6}

![Fig S7. Empirical coverage at 50% and 90% prediction intervals by age group for each model configuration.](../output/figs/supp/cov_by_age_group.png){#figs7}

### Model permutation study

![Fig S8. Daily nowcasts overall from all age groups arrange in three facets (by row), with each showing the baseline validation model alongside variants from a specific permutation category: top row shows training data volume variations, middle row shows reporting triangle completeness variations, and bottom row shows borrowing strategy variations. Each model configuration has a consistent, distinct colour across all panels, with the baseline validation approach highlighted in black. Observed data are shown as solid lines with gray indicating data available at the nowcast date and red indicating evaluation data.Nowcasts are shown daily with a 14-day horizon.](../output/figs/supp/nowcasts_over_time_ntl.png){#figs8}

![Fig S9. Absolute WIS by nowcast horizon for each model configuration. Colour by model configuration, decomposed by dispersion, overprediction, and underprediction.](../output/figs/supp/mp_wis_by_horizon.png){#figs9}

![Fig S10. Absolute WIS by age group for each model configuration. Colour by model configuration, decomposed by dispersion, overprediction, and underprediction.](../output/figs/supp/mp_wis_by_age_group.png){#figs10}

![Fig S11. Absolute WIS over time (by week) for each model configuration. Colour by model configuration, decomposed by dispersion, overprediction, and underprediction.](../output/figs/supp/mp_wis_by_nowcast_week.png){#figs11}

### Case study: UKHSA norovirus surveillance

![Fig S12. Absolute WIS over time (by week) for each model.](../output/figs/supp/wis_over_time_noro.png){#figs12}

![Fig S13. Absolute WIS by day of week for each model.](../output/figs/supp/wis_by_weekday.png){#figs13}

![Fig S14. Empirical coverage at 50% and 90% prediction intervals for each model.](../output/figs/supp/noro_coverage.png){#figs14}

![Fig S15. Empirical coverage at 50% and 90% prediction intervals by day of week for each model.](../output/figs/supp/noro_cov_wday.png){#figs15}

## References
